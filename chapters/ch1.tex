% !TeX root = ../main.tex

\chapter{绪论}

\section{研究背景与意义}
党的二十大报告指出：发展海洋经济，保护海洋环境，加快建设海洋强国。近年来，随着社会经济的不断发展，人类的生产活动对于各种资源如石油、土地、天然气以及生物资源的需求也不断增加，陆地资源的不断减少使得人们将注意力转移至海洋资源。
海洋蕴藏着丰富多样的生物和矿产资源 \cite{ocean_energy}，与陆地相比，人类对于海洋资源的开发仍处于探索阶段。
随着各种海洋研究和勘探作业如水下观测、海底电缆或管道维护、水下考古遗址测绘和重建等任务的发展，
使得水下自主导航需求不断增加，自主潜水器（Autonomous Underwater Vehicle, AUV）和遥控潜水器（Remotely Operated Vehicle, ROV）己逐渐被应用在海上作业中 \cite{auv}\cite{rov}。
有些需要极高灵巧操作的水下任务还需要依靠人工完成，一些水下可穿戴设备可以在人类进行水下活动时提供必要的帮助 \cite{Xia2022}，例如柔性外骨骼可以为髋关节内收提供辅助扭矩来增强人类水下活动 \cite{Xia2023}。
除了实现运动增强之外，水下图像也是认知水下信息的重要手段之一，在海洋勘探领域中一直占据着重要地位。\cite{underwater_perception}
AUV、ROV等水下机器人通过在设备终端配置水下相机来采集水下图像、视频数据，常常用于协助人类执行海洋勘探任务，采集到的数据将会被应用下水下科研领域，进而推动人类对海洋环境的探索与认知，因此高质量的水下图像对促进海洋勘探的发展意义重大。

然而，恶劣的水下环境给水下成像带来了一定的问题：一方面，水作为介质会不同程度地吸收不同波长的光，导致水下图像的色彩失真；另一方面，水中的悬浮颗粒会使水下光线产生轻微的角度偏转，导致图像的细节模糊。

失真的水下图像不仅会使观察者获得欠佳的视觉体验，还会对AUV、ROV等水下机器人上所搭载的视觉系统的正常运行产生严重干扰。
为了应对水下图像因光照匮乏而产生的问题，水下视觉系统常常会配备人工照明光源。然而，人工照明光源往往存在非均匀性的特点，这致使水下图像呈现出中间区域亮度偏高，整幅图像的亮度分布不均衡的状况，进而对成像的品质造成影响。
此外，鉴于水下成像环境的复杂性，水下成像系统难以从根源上消除由光散射所引发的图像模糊以及噪声的不良影响，所以仅仅依赖先进的成像设备是远远无法满足需求。

伴随计算机技术的迅猛进步，数字图像处理技术取得了显著的发展，逐渐走向成熟，并且在众多领域（诸如医学、军事、监控、遥感等）均发挥着关键作用。
相较于提升成像系统设备性能所需的高昂成本，数字图像处理的方式更为灵活便捷，易于实施。
因此众多研究人员专注于运用数字图像处理技术来优化水下图像的视觉效果，提高成像质量，
水下图像处理技术也日益受到工业届和学术界的重视，越来越多的图像增强算法映入眼帘，在改善水下图像成像质量方面有着重要的应用，也可以便于后续水下识别、分割等任务的展开，极大地推动了海洋开发与勘探的发展。

由于在各类水下环境中光所遭受的衰减与散射程度不尽相同，尽管水下图像普遍展现出亮度较低、细节模糊的特征，然而在偏色状况以及模糊程度上，不同环境下的图像依然存在差别，因而难以进行统一的处理操作，这一情况为水下图像增强算法的研究增添了极大的困难。
当前，具备良好鲁棒性且切实有效的水下图像增强算法数量极为有限，多数算法仅仅能够针对单一或少数几种水体环境来实施图像增强处理，无法应对复杂多变且种类繁多的水体环境，这在很大程度上制约了这些算法的实际应用范围。
而且目前的图像增强算法对于所处理的图像分辨率大小也有所限制，特别是对于高分辨率的原始图像输入来说，许多算法需要重新设计，这给算法的实际应用带来了困难；
因此依靠图像处理算法鲁棒且稳定地增强水下图像仍是一个极具挑战性的任务。

另外，在需要人亲自参与的水下作业任务中，如何以一种有效的方式将对采集的视觉图像进行处理并反馈给潜水员，从而提高潜水员在水下的感知能力，也是需要解决的问题。\cite{underwater_perception}
基于增强现实（Augmented Reality, AR）的可穿戴设备是一种具有广阔前景的实现方式，将处理好的场景信息以三维可视化的途径呈现给潜水员，将有效提升潜水员在水下的感知能力。
目前主流的水下场景重建包括两个方向，一是以深度传感器如声纳为基础的水下稀疏或稠密点云的构建，另一个方向是基于视觉图像的水下三维重建研究，
其中基于新视角生成的逼真场景重建具有更强的适用性，尤其是对水下人体穿戴式设备来说，可以自然地实时渲染出媲美现实中的画面。
但是由于水下环境中存在的图像退化以及水流带来的场景动态扰动，使得水下环境除了采集的图像质量差外，也难以保持一个完全静态的场景，
实际进行新视角生成时要考虑场景的动态影响，包括水流带来的运动变化和光照不均匀带来的颜色变化，但是目前没有真正针对水下这种特殊场景进行去除扰动的重建研究。

综上所述，针对环境多变、条件恶劣的水下环境现状与实际场景需求，目前亟待解决的问题如下：

（1）水下图像增强算法局限大：大多数图像增强算法对于水下图像来说缺乏适应性，一些去雨、去雾建模中忽略的因素在水下图像增强问题中需要重新考虑，比如水陆环境不同透射率的影响。
采用更强大的复杂模型或框架在一定程度上可以提升模型的泛化能力，但是需要足够多的高质量数据集来支撑。
与去雨、去雾问题相比，水下图像增强问题不仅在真实环境下获得水下退化和清晰的成对图像难度巨大，且采用合成数据的方式获取成对图像数据集也极为困难，
现有的依靠物理模型合成水下图像数据集的方式，往往通过简化模型来生成有色偏和雾效应的图片，并不能精确描述水下环境。
另外，许多模型往往是针对固定的图像分辨率进行训练，高分辨率的图像输入往往需要重新设计模型，这给模型的实际应用带来了困难。

（2）水下三维建模能力弱：劣质的水下环境会对图像的语义信息带来干扰，这让一些依赖图像语义的下游任务带来挑战。在三维重建的前期数据预处理阶段，
采用这种退化的水下图像进行相机位姿估计时，会因关键点匹配错误导致相机位姿估计结果不准确，从而影响点云生成结果。
另外由于水流造成的动态扰动，会使得不同时刻的场景发生轻微变化，这导致最终的渲染时场景中的某些位置会出现模糊，影响视觉效果，
而加入时间信息进行时空建模时又需要考虑由于模型复杂度提升带来的推理成本问题，影响原本的渲染效率。

（3）缺乏行之有效的感知增强系统：对于复杂的水下任务如事故救援打捞，水下勘探等情况，人类的灵巧操作难以被水下机器人取代，而人在水下环境中的各视觉感官被严重削弱，
通过在人体水下可穿戴设备上集成感知增强功能可以辅助潜水员在水下环境中的工作，但是目前很少有类似的系统能够将水下环境信息以一种直观、清晰的方式呈现给潜水员。
同时可靠的人机交互也是提升潜水员在使用水下设备时体验的关键，复杂的交互指令往往需要潜水员花费大量的时间学习，这会降低潜水员在水下作业的效率，
亟须一种自然、直观的交互方式提高潜水员在使用系统时的体验。

% （1）模型局限性大
% 与去雨、去雾问题相比，水下图像的建模更为复杂也更为精细。去雨、去雾建模中忽略的一些因素和近似的一些参数，在水下图像增强问题中需要重新考虑，比如水陆环境不同对透射率的影响。除了复杂的水下图像建模过程，传统方法增强水下图像会采用若干已知先验来加强模型对水下环境的刻画，涉及到调整各个约束项之间权重大小，需要人工协调，时间代价昂贵。基于先验的增强方法的优劣程度取决于模型对真实环境的刻画是否完善，对于繁多复杂的水下环境的适应性是否优良，采用的约束是否精确，但是这需要对任务深刻的理解和高超的数学建模技巧以及大量的时间。

% （2）数据获取难度大
% 基于深度学习的水下图像增强方法依赖大量的数据，解决越复杂的问题，网络需要越大的参数量。数据量越大，深度模型鲁棒性越好。同样与去雨、去雾问题相比， 水下图像增强问题不光在真实环境下获得水下图像和清晰的图像难度巨大，采用合成数据的方式获取图像对数据集也极为困难。现有的依靠物理模型合成水下图像数据集的方式，往往通过简化模型来生成有色偏和雾效应的图片，并不能精确描述水下环境。 图像对采用的干净图像往往是陆上的干净图像，这与水下环境并不类似。因此，图像对数据集的缺失为水下图像增强问题的解决带来了困难。

% （3）泛化能力弱
% 目前基于深度学习的水下图像增强算法仍依赖于指定的训练测试集，对于复杂多变的真实场景的水下图像，即训练集尚未包括的水下环境类型，图像增强的结果并不能让人满意，如何扩展数据集，适配多种复杂环境下的水下图像成为水下图像增强算法和实际应用中的巨大挑战。

本文将从水下图像增强问题出发，结合水下场景需求，提出一种基于去噪扩散模型与3D高斯泼溅的水下三维感知增强系统，
通过将采集到的原始数据通过图像增强算法生成高质量的水下图像，并利用3D高斯泼溅得到优化后的三维可视化模型，
最后借助可穿戴设备和手势交互指令为潜水员提供更加直观、清晰的水下环境信息，从而提高水下作业的效率。


\section{国内外研究与发展现状}
\subsection{水下图像增强技术国内外现状}
目前水下图像增强技术大致可以分为以下三类：基于物理模型的方法、基于先验知识的方法和基于深度学习的方法。
\subsubsection{基于物理模型的方法}
基于物理模型的方法依赖于水下图像生成过程的数学模型来增强水下图像 \cite{uw_img_math1}\cite{uw_img_math2}：
\begin{equation}
I=J \cdot e^{-\beta d}+B^{\infty} \cdot\left(1-e^{-\beta d}\right),
\label{IFM1}
\end{equation}
其中$I$是水下退化后的图像，$J$是未衰减的图像，$B^{\infty}$是大气光照， $\beta$是衰减系数，$d$是相机到物体的距离。
该模型与陆地图像恢复方法中常用的图像生成过程模型类似 \cite{ifm}，用数学模型从退化原理出发表示了水下图像的衰减与散射过程。
2018年，Akkaynak等人\cite{modified_uw_img_math}通过使用$\beta^D\left(\mathbf{v}_D\right)$和$\beta^B\left(\mathbf{v}_B\right)$修正其中的前向衰减系数和后向衰减系数更新了水下图像生成数学模型：
% \begin{equation}
% I_c=J_c e^{-\beta_c^D\left(\mathbf{v}_D\right) \cdot z}+B_c^{\infty}\left(1-e^{-\beta_c^B\left(\mathbf{v}_B\right) \cdot z}\right)
% \label{IFM2}
% \end{equation}
\begin{equation}
    I=J e^{-\beta^D\left(\mathbf{v}_D\right) \cdot d}+B^{\infty}\left(1-e^{-\beta^B\left(\mathbf{v}_B\right) \cdot d}\right).
    \label{IFM2}
\end{equation}

还有一些利用其他辅助信息进行图像恢复的方法，如基于深度图\cite{depth_img}、连续的多帧图像\cite{multi_frame}和偏振图像\cite{U2PNet}等信息的水下图像增强算法。
这些方法可以更好的估计水下图像生成模型中的参数并获得清晰的图像。
多源传感器的信息融合技术\cite{fusion}可以依靠语义补充来提升水下图像增强的表现，然而它们通常需要特定的硬件支持，如 RGBD 相机和偏振相机。
总的来说，基于物理模型的方法系统地描述了水下图像的生成过程，并为水下图像增强提供了一个参考模型，对水下图像增强任务具有一定的理论指导作用，
但是假设的模型在适应复杂多样的水下环境方面仍然面临挑战，准确估计多个参数仍然是一项具有挑战性的工作。

\subsubsection{基于先验知识的方法}
基于先验知识的水下图像增强方法主要是利用从图像亮度、颜色、对比度等因素总结出的统计学规律来恢复图像质量。
与物理模型方法相比，这类方法通常不需要额外设备支持，仅通过对单张图像的处理即可达到增强效果，因此在实际应用中具有更强的灵活性。
根据先验知识的不同级别可以将基于先验知识的水下图像增强方法分为传统图像处理方法和高级统计推断方法两大类。

第一种方法涉及应用传统的图像处理技术，根据常规的先验知识将图像亮度和饱和度等图像属性恢复到正常水平，例如：直方图均衡（Histogram Equalization, HE）\cite{he}、对比度限制自适应直方图均衡（Contrast Limited Adaptive Histogram Equalization, CLAHE）\cite{clahe}、伽马校正和广义反锐化掩蔽 (Generalized Unsharp Masking, GUM) \cite{gum}，
这类方法不考虑水下图像的成像过程，直接通过直方图拉伸或线性变换等方法对颜色模型中的像素进行修改，以扩展图像的动态像素范围，提高图像对比度并缓解图像色偏问题。
2013 年，Hitam 等人\cite{mixture_clahe}提出一种专门适用于水下图像增强的 CLAHE 方法， 他们在由色调、 饱和度和明度构成的色彩空间（Hue Saturation Lightness, HSL）和由红色、绿色和蓝色构成的色彩空间（Red Green Blue, RGB）上进行 CLAHE 运算，并使用欧几里德范数将两个结果组合在一起，有效提高了水下图像的对比度，并降低了图像中的噪声和伪影。
Retinex 是一种基于颜色恒常性理论的经典图像增强方法，
2014 年，Fu 等人\cite{uw_retinex}提出基于 Retinex 模型的水下图像增强方法，采用了 Retinex 的水下图像处理变分框架，他们从水下退化图像中分解出反射分量和照明分量，可以有效恢复图像亮度和校正图像色彩。
但这些方法都缺乏系统指导，不具备很强的泛化能力。

基于高级统计推断的先验方法通过统计正常图像中的潜在规律来估计水下图像生成模型中的相关基本参数，从而实现图像质量提升。
这些方法源于特定环境下的图像先验知识，在多种场景中具备一定的泛化能力。
何等人 \cite{dcp} 通过观察大量无雾图像的暗通道图数据，发现正常无雾图像的暗通道几乎为零，于是提出了一种名为暗通道先验（Dark Channel Prior, DCP）的图像去雾算法，在图像去雾任务中取得了令人惊叹的结果。
受到暗通道先验算法在陆地天气去雾为主的一系列任务中取得成功的启发，2013 年，Drews 等人 \cite{udcp}对传统的暗通道先验算法进行了水下的改进，提出一个新的仅考虑绿色和蓝色通道的水下暗通道先验方法（Underwater Dark Channel Prior, UDCP），更加符合水下环境中短波红色光被严重衰减的背景。
然而，由于水下环境复杂，统计出的先验知识可能在某些情况下失效，导致形如DCP这一类的方法在水下可能会表现出亮度或者色彩恢复的不稳定性，甚至在一些极端的水下环境中出现失真或细节丢失的问题。

\subsubsection{基于深度学习的方法}
与传统的基于物理模型和先验知识进行水下图像增强的方法不同，基于深度学习的方法可以基于神经网络从大规模成对数据中学习到图像特征和潜在的非线性映射关系。
神经网络模型通过构建复杂的网络结构，可以有效地捕捉图像中的低光、噪声、色彩偏移等特性，并在增强过程中实现对图像细节的高保真还原。
因此，深度学习方法在处理复杂的水下图像时展现出强大的适应性和鲁棒性。
经典的深度学习方法往往以有监督学习的方式，经过多次的卷积和反置卷积操作进行特征提取和恢复来重建清晰的图像。
这些方法在图像处理领域已经展现了显著效果，如在图像超分辨率\cite{cyberCSRnet}、图像去雾\cite{QCNN_H}、曝光校正\cite{Exposure_restoration}和语义重建\cite{InpaintingMissingArea}等任务中都涌现出许多优秀的算法。
有监督的深度学习方法旨在通过对应的特征解码器和编码器以数据驱动的方式学习权重来恢复水下图像，即算法需要用包含原始水下图像和其对应理想参考图像的数据集来进行训练和评估。
2020 年，Anwar 等人 \cite{uwcnn}提出了 UWCNN 水下图像增强算法，他们引入了一种专门用于水下场景图像增强的卷积神经网络（Convolutional Neural Network, CNN）模型，并且使用从现实世界陆地图像生成的各种合成水下风格图像来训练模型学习图像的恢复模式，
然而，由于训练数据的合成性质，这种方法在模型的泛化性上表现不佳。

由于水下理想参考图像获取困难，研究人员很难同时获取真实的水下场景和其相应的理想参考图像，因此现有深度学习增强方法多流行使用基于生成对抗网络(Generative Adversarial Network, GAN) \cite{gan}的方法避免对参考图像的依赖。
GAN 通过生成器和判别器之间的对抗训练，可以生成更真实且无噪声的水下图像。
2018 年， Li 等人 \cite{water_gan}提出了 WaterGAN 方法，该方法以 RGB 图像以及对应的深度图分别作为输入，从而将网络分为水下图像合成和颜色恢复两个部分，图像合成部分用于输出合成水下图像，颜色恢复部分将未经标记的水下图像作为输入，输出恢复后的图像及对应深度图。
同年，Fabbri 等人 \cite{ugan}提出 UGAN，该方法只需输入单张图像，不需要深度图等额外信息的输入，实现了对水下彩色图像的有效增强。
2019 年， Chen 等人 \cite{gan-rs}提出的 GAN-RS 利用多个判别器来引导生成器抑制水下噪声，多个鉴别器可以让GAN-RS 进一步增强生成器生成更真实且无噪声的水下图像的能力。
2020 年，Islam 等人 \cite{funie_gan}提出了一个快速水下图像增强算法 FUnIE-GAN，并将其应用到了水下机器人的目标检测以及人类姿势检测任务中。作者还利用 CycleGAN \cite{cycle_gan}生成了一个名为 EUVP（Enhanced UnderwaterVision Dataset）的大型水下数据集，其中包含数万张已配对的水下图像。
2021 年，Zhu 等人 \cite{dehaze_gan}提出了 DehazeGAN，这是一种利用多尺度生成器来预测水下图像生成模型中的大气光和传输图的方法，实现通过结合 GAN 与 水下图像物理生成模型来恢复水下图像。
但由于GAN无法控制生成样本的模式，训练过程经常会遇到收敛困难等问题，同时由于水下场景的复杂性和多样性，基于预训练的 GAN 模型在对不同数据集进行迁移微调时容易发生训练不稳定与崩溃现象，
因此基于 GAN 的水下图像增强方法在鲁棒性和泛化方面表现依旧不够理想。

与 GAN 相比，去噪扩散概率模型 \cite{pre_ddpm}\cite{ddpm}是一种基于概率似然的模型，且在近年来已经证明了其具有生成高质量图像的能力。
去噪扩散模型以其简单性和可扩展性而闻名，该模型可以从简单的初始噪声分布中逐步生成逼真且高质量的图像，在许多任务中展现出超越GAN的结果，这使其对包括水下图像增强在内的各种图像生成任务具有吸引力。
2021 年，OpenAI 的研究人员通过实验证明扩散模型相比 GAN 在大多数任务中可以表现的更好，并且他们提出了一种由分类器引导的扩散训练方法\cite{ddpm_beat_gan}，确保生成的样本保持其真实性并与目标样本分布保持一致。

然而，去噪扩散模型需要经过大约上千个去噪步骤来生成最终的结果，这导致其推理速度较为缓慢，特别是在生成高分辨率图像时需要很长的时间。
2022 年，Rombach 等人 \cite{latent}借助自动编码器，提出一种在图像潜在空间进行扩散训练的方法，以在降低复杂性和保持图像细节之间实现近乎最优的权衡。
另一种加速扩散模型推理时间的方法是缩短扩散模型的反向采样步骤，如改进的隐式扩散方法 \cite{improved_ddpm,ddim}设计了一种新的采样器，可以用更少的时间步数进行去噪采样，从而加速扩散模型的推理过程。
通过利用这一改进，扩散模型中的采样过程变得更加高效，并且可以在预训练的扩散模型中直接使用，无需重新训练模型，有助于增强扩散模型在不同任务上的的整体性能和可扩展性。
2023年，Özdenizci 等人 \cite{weather}利用条件扩散模型在恢复恶劣天气条件下的图像研究中取得了卓越效果，他们提出了一种基于补丁的方法来恢复不同尺寸的图像。
然而，他们将图像分辨率统一为 16 的倍数，以便于获得补丁块，但这仍然引入了图像在像素空间的重新调整，导致图像生成过程中的像素细节丢失。

总的来说，基于目前去噪扩散模型在图像生成领域相比GAN表现出的优越性，可以看出去噪扩散模型在水下图像增强方面具有一定的潜力，尽管其生成时间较长，但可以利用在潜在空间采样或者借助隐式扩散采样的方式提升模型效率。

\subsection{水下三维重建技术国内外现状}
探索水下三维场景重建技术对于海洋工程、环境保护等具有重大意义。
近年来，国内外研究人员围绕该技术的关键问题展开了深入研究，主要集中于以下两个方向。

\subsubsection{传统三维点云重建方法}
传统三维点云重建的一种方法是基于深度传感器（如声纳、激光等）等设备，通过采集水下环境的稀疏或稠密点云实现三维建模 \cite{sonar1}\cite{sonar2}，
深度传感器在水下环境中表现出较强的抗干扰能力，但受限于设备成本及数据处理复杂性，其应用仍面临较大挑战；
另外，基于计算机视觉的点云生成也是一种重要的水下三维重建方法，代表性技术包括SfM（ Structure from Motion）\cite{sfm1, sfm2} 和MVS（Multi-view Stereo） \cite{mvs}。
SfM通过分析多视角图像的几何关系生成稀疏点云，而MVS则进一步利用多幅图像的视差信息进行三角测量，从而生成高精度的稠密点云。
这两种方法都需要对来自不同角度的图像进行特征提取和匹配，常用算法如SIFT \cite{sift} 和 ORB \cite{orb}，在图像特征点对齐方面具有较高的可靠性。
并且近年来随着机器学习的引入，极大地提升了图像特征匹配的精度。
例如，2023年Lindenberger等人 \cite{lightglue} 提出了基于神经网络的图像特征匹配方法，该方法通过跨图像的局部特征学习，在提升匹配精度的同时，大幅降低了内存和计算需求。
2024年，Wang等人 \cite{enhancing-mvs} 引入了Twin-FPN架构，结合多尺度特征损失，在复杂的室内场景中实现了更高效的通用特征表示。

然而，传统三维重建方法在水下应用中受到诸多限制，传统的三维点云不利于潜水员直观的理解水下环境，单纯的点云数据无法观察水下物体的细节纹理，这对一些需要精细操作的场景，如水下管道维护、水下考古等场景来说，存在较大的局限性。


\subsubsection{基于图像的新视角生成}
基于视觉图像的水下三维重建除了可以形成场景的点云表示\cite{vision_recon} ，也可以通过新视角生成（Novel View Synthesis, NVS）技术渲染出更逼真的任意视角的新图像，
其更多应用在水下人体穿戴式设备中 \cite{Xia2023}\cite{underwater_perception}，可以极大地增强用户的环境感知能力，推动水下增强现实技术的发展。
神经辐射场（Neural Radiance Fields, NeRF） \cite{nerf}\cite{Mip_nerf360} 是NVS领域中的一类代表性框架。
NeRF通过定义隐式函数来表征三维场景，并通过体积渲染 \cite{volume_render} 方法生成高质量的多视角图像。
然而，由于在光线行进路线上的频繁采样让NeRF具有高额的计算成本，限制了其在实时场景渲染中的应用。
为此，2022年提出的Instant NeRF \cite{instant_nerf} 通过多功能编码器显著降低了NeRF的训练成本，允许在几乎不牺牲质量的情况下利用较小的网络来大大减少浮点运算和内存访问次数。
此外，2023年Cao等人提出了HexPlane方法 \cite{hex_plane}，通过高效的融合从不同二维平面中提取的向量来计算时空点的特征，在动态场景上将训练时间减少了100多倍。

与NeRF的隐式表示不同，3D高斯泼溅（3D Gaussian Splatting， 3DGS） \cite{3DGS} 提供了一种显式的场景表示方法，其可微分的光栅化渲染方式相比NeRF的体积渲染方式拥有更加优秀的渲染速度，
得益于其极短的训练时间、高效实时渲染能力以及超越 NeRF 类SOTA方法的渲染质量，3DGS迅速引起了学术界和工业界的广泛关注。
借鉴动态 NeRF 的研究成果以及3D高斯可变形扩展能力，通过引入时间维度可以相对直观的实现动态场景的重建\cite{dynamic_3DGS1}\cite{dynamic_3DGS2}\cite{dynamic_3DGS_efficient}\cite{4DGS}。
2024年，Guo等人\cite{flow_2024motion}为了更好的捕捉场景中的动态信息，通过在训练中增加光流损失对变形范式进行优化，建立了高斯运动和图像像素流之间的对应关系，提高了3DGS在动态场景建模时的质量。

针对开放场景的场景的静态重建中经常面临的跨图像外观差异与瞬态遮挡物干扰问题，
已经有研究尝试通过多种策略来应对这些挑战：NeRF-W\cite{nerf-w}为每幅图像分配一个外观特征向量，并在神经辐射场中引入瞬态置信度，实现外观感知的静态、瞬态物体分离建模。
但受限于 NeRF 本身固有的重建和渲染效率，单场景训练需达数十小时，单帧渲染耗时数十秒，严重影响其在真实场景中的应用。
近期基于3DGS 的工作SWAG\cite{swag}大幅提升了训练与渲染速度，但其仍沿用 NeRF-W的逐图像分配外观特征向量策略，导致需使用测试集图像的一半来训练额外外观特征向量。
而水下环境相比于上述的户外开放场景还存在固有的色偏问题，初始采集的图像会出现全局的色彩退化，
这不仅给3DGS的训练带来挑战，还导致自有数据集在有限条件下利用算法进行相机位姿估计变得困难。

综合以上对水下图像增强和三维重建技术的研究现状，可以看出去噪扩散模型和3D高斯泼溅技术在水下图像增强和三维重建任务中具有一定的潜力，但目前仍存在以下问题：

（1）水下图像增强方面，目前基于去噪扩散模型的系列方法在陆地图像增强方面已经取得了较好的效果，但其在水下图像增强方面的应用仍处于起步阶段，问题在于：
一是需要采用合理的策略解决水下图像数据集获取困难与扩散模型数据规模依赖之间的矛盾；
二是在实际应用中正确处理扩散模型推理成本高与生成质量高之间的矛盾。
% 角色定位

（2）水下三维重建方面，基于图像的新视角生成技术可以结合可穿戴设备提供给潜水员更直观的视觉感知，但目前还没有相关的研究将3DGS技术应用于水下三维重建，问题在于：
一是本身缺少水下三维重建数据集，模型有效性在水下难以得到有效验证；
二是需要在水下动态环境中考虑运动干扰，同时保留原始3DGS的高效渲染能力。


\section{本文主要工作与组织结构}
\subsection{本文主要工作}
基于上述对水下图像增强任务以及三维重建工作的研究现状与问题分析，本文针对目前水下图像恢复难、水下三维感知质量差等问题，提出了基于去噪扩散模型以及3D高斯泼溅技术的水下图像增强以及三维重建方法，
% \cite{patch_based_ddpm}
并在此基础上结合水下可穿戴式平台设计一套有效的水下三维增强感知系统，用于辅助潜水员在进行水下作业时实时预览目标场景的三维信息。
\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{figures/ch1/overview.pdf}
    \caption{本文主要研究内容}
    \label{img:overview}
\end{figure}

本文的主要研究内容如图\ref{img:overview}所示，包括以下几个方面：

（1）本文提出一种基于补丁（Patch）引导采样过程的去噪扩散模型方法，并结合补丁大小重新设计噪声估计网络结构，利用条件扩散模型实现水下图像的增强。
这种补丁级别的处理方式不仅缓解了扩散模型对数据规模的依赖，同时让提出的方法突破分辨率限制，适用于任意分辨率图像的处理。
同时，考虑扩散模型的推理速度与生成能力之间的矛盾，该算法的结果主要用来为接下来的三维重建提供高质量的多视角图像，而不用考虑其实时性差带来的担忧。
% \cite{patch_based_ddpm}

（2）本文提出一种基于3DGS的水下三维重建方法。结合4D动态高斯泼溅技术在动态场景重建中的能力，本文设计了一种多阶段的递进式训练模式，
通过筛选出原始数据集中的高频次目标场景，实现水下目标场景的高质量重建，从而保留原有3DGS的渲染速度，
并制作了专门的水下三维重建数据集，用于验证提出的方法在复杂水下环境中的重建效果。

（3）基于增强现实技术，本文搭建了一套可适用于水下作业的穿戴式平台，结合预训练的水下3D高斯模型为潜水员提供一个可以自由控制视角的三维场景预览画面，
同时提出一种基于手势识别的人机交互方法，潜水员可以利用手势控制预览画面中的视角，从而实现对水下场景的实时感知，具有较强的实用性和应用前景。
% \cite{underwater_perception}

% （1）技术前沿性：随着深度学习技术的发展，去噪扩散概率模型在图像生成领域逐步取代生成对抗网络的在许多任务中的应用，本文拟将去噪扩散概率模型和去噪扩散隐式模型应用于水下图像增强，该技术代表了图像生成领域的前沿发展，具有强大的图片编辑能力；同时，3D高斯泼溅技术在三维重建领域取得了显著的进展，本文拟将3D高斯泼溅技术应用于水下三维重建，该技术具有高效的渲染速度和质量，能够实现动态场景的实时表示。

% （2）创新处理策略：在水下图像增强方面，

% （3）系统完整性：本文将水下图像增强技术和水下三维重建技术相结合，设计一套完整的水下三维增强感知系统，该系统能够提高水下图像质量和三维场景重建精度，为水下作业提供辅助感知增强，具有较强的实用性和应用前景。

\subsection{本文组织结构}
第一章绪论：本章主要阐述了研究背景和意义，强调在海洋资源开发需求增长的背景下，水下图像和三维感知对于海洋勘探的重要性，以及当前水下环境成像面临的问题和挑战。同时，详细分析了水下图像增强和三维重建技术的国内外研究现状，明确了现有方法的不足，进而提出本文旨在解决水下图像恢复难、三维感知质量差等问题，通过基于去噪扩散模型和3D高斯泼溅的技术，设计水下三维感知增强系统，辅助潜水员水下作业。

第二章相关技术与理论：对支撑本研究的核心技术进行了系统介绍，包括去噪扩散概率模型、去噪扩散隐式模型、3D高斯泼溅技术，以及U-Net网络和Kolmogorov-Arnold网络。这些技术为后续章节中水下图像增强算法和三维重建框架的设计提供了坚实的理论基础。

第三章基于去噪扩散模型的水下图像增强算法：针对水下图像存在的语义衰减问题，提出了基于补丁引导的去噪扩散模型水下图像增强算法。该算法通过基于滑动窗口的补丁获取方式，将图像分解为固定大小的补丁，降低了模型对数据集规模的依赖，同时实现了对任意分辨率水下图像的增强。在采样过程中，利用条件扩散模型原理，将退化的水下图像作为条件信息引入，确保生成结果的保真度。此外，设计了专门的噪声估计网络，通过引入残差模块和注意力机制，提升了噪声预测的精度。通过在EUVP和UIEB数据集上的实验，与多种现有方法对比，验证了该方法在水下图像增强方面的有效性，在主观视觉效果和客观指标上均表现出色。

第四章基于3D高斯泼溅的水下三维重建：鉴于3D高斯泼溅技术在新视角生成领域的优势以及水下三维重建面临的挑战，如缺少专门数据集、图像退化和动态扰动等问题，提出了基于3D高斯泼溅和KAN变形机制的水下目标场景三维重建方法。通过设计3D高斯时空编码器和基于KAN的特征解码器，实现了对水下动态场景的4D时空建模优化，提高了重建的精度和稳定性。采用多阶段训练模式和场景过滤模块，有效抑制了运动干扰，提升了静态场景的重建质量。构建了水下重建数据集3DUW，并在该数据集和公开数据集SeaThru-NeRF上进行实验，结果表明该方法在水下场景重建的准确性和实时性方面具有显著优势。

第五章水下穿戴式感知增强系统设计：为提升潜水员在水下复杂环境中的感知能力，基于前文提出的水下图像增强算法和三维重建技术，设计了可穿戴式水下感知增强系统。在需求分析方面，明确了系统需具备水下视觉增强、实时三维渲染、可靠运行平台和自然人机交互等功能。通过可行性分析，从视觉增强功能完整性、系统实时性、可靠性和人机交互等角度论证了系统设计的可行性。在系统实现上，完成了硬件选型与系统架构搭建，包括相机、头戴式显示器、嵌入式处理器和电源模块等的选择和平台的防水与机械设计。同时，集成了图像增强与三维重建、用户交互与控制以及增强现实界面设计等功能，为潜水员提供了全面且清晰的水下环境信息，提升了水下作业效率。

第六章总结与展望：总结了全文的研究成果，回顾基于去噪扩散模型和3D高斯泼溅技术在水下图像增强和三维重建任务中的优势和创新点。同时，对未来的研究方向进行展望，指出当前研究存在的不足，如显示屏分辨率有待提高、功能可进一步扩展等，并提出了相应的改进方向和研究思路，为后续研究提供参考。 
