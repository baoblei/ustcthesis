% !TeX root = ../main.tex

\chapter{基于去噪扩散模型的水下图像增强算法}
水下图像由于红光快速衰减和悬浮颗粒的光散射作用，通常会出现显著的色偏和模糊，
这种退化效应会削弱水下图像的原有语义，严重限制许多水下图像下游任务（如目标检测或语义分割）的表现。
尽管基于生成对抗网络的图像增强方法在一定程度上可以缓解这一问题，但其固有的对抗训练机制容易在训练和迁移过程中发生模式崩溃，在各种应用场景下的效果不稳定。
为解决上述问题，本章提出一种基于补丁引导的去噪扩散模型水下图像增强算法。
该方法结合扩散模型的强大图像生成能力与补丁级别的采样策略，以提高处理效率和生成图像的细节质量。
算法基于扩散模型训练框架，以原始图像作为生成条件，设计了融合补丁引导采样的优化流程，并调整了扩散模型噪声估计网络结构以适配补丁级别的训练模式，从而提高去噪阶段的估计精度。
在实验部分详细介绍了所用数据及评价指标，并通过与多种现有方法的对比，验证了该方法在水下图像增强中的有效性。

% 水下图像往往由于红光的衰减与悬浮物的反射而出现严重的色偏与模糊，导致许多下游任务由于缺乏有效的语义信息而受到限制。
% 虽然基于生成对抗网络的方式已经取得了不错效果，但是会遭遇对抗训练固有的模式崩塌问题。
% 针对生成对抗网络的瓶颈，本章将介绍基于去噪扩散模型的水下图像增强算法。
% 利用基本的扩散模型训练框架，将原始图像作为生成条件，融合补丁引导的采样过程来提高模型的处理效率和图像细节，
% 并且重新设计了适用于补丁大小的U-Net网络结构来估计去噪阶段的噪声，
% 最后详细描述了实验数据和评价指标，通过与其他模型的对比，全面论证所提出的方法对水下图像增强的有效性。

\section{基于补丁引导的水下图像去噪扩散采样过程}
扩散模型具备强大的学习图像先验的能力，在各种图像生成领域上表现出卓越的生成质量。
然而，扩散模型的训练通常比较依赖训练数据集的规模，在小样本数据集下生成的图像容易出现伪影或错误。
为解决这一问题，本章提出一种基于水下图像补丁引导的去噪扩散方法，
通过将图像分解为固定大小的补丁以学习局部的扩散先验，在目前水下数据集样本较少的背景下，
显著降低了模型对数据集规模的依赖，同时也可以实现任意分辨率水下图像的增强。

\subsection{基于滑动窗口的补丁获取}
本文首先采用滑动窗口将图像分解为多个重叠补丁，以作为去噪扩散模型的直接输入，
其中滑动窗口的步长 $s$ 小于补丁大小 $p$，从而在分解的补丁之间形成重叠，以保证生成采样过程中图像局部之间形成自然过渡。
然而，在特定步长和补丁大小的组合下，可能出现以下两种问题：
（1）边缘像素丢失：当窗口无法完全覆盖图像边缘部分时，会出现未裁剪区域。若采用先验值填充（如利用局部均值填充边缘像素），
在多重去噪阶段会逐步扩散该部分的误差，形成全局性错误；
（2）尺寸不一致：直接丢弃边缘区域的像素会导致生成图像尺寸与原图不一致，无法真正意义上实现任意分辨率的水下图像增强。
为解决上述问题，本文对图像边缘又进行了额外分解，确保最终获取的补丁集合能够完整覆盖整个图像，避免任何像素的丢失，同时防止误差扩散。
\begin{algorithm}[ht]
\caption{补丁获取方法}
\label{alg:patch}
\KwIn{任意分辨率的图片输入 $\bm{X}$，输入图像 $\bm{X}$ 的宽度 $W$ 和高度 $H$，滑动窗口的步长 $s$，补丁以及滑动窗口的大小 $p$}
\KwOut{提取的补丁 $\mathbf{x}^{(i)}$ 和补丁位置 $\bm{P}_i$}
\SetKwInOut{Input}{输入}
\SetKwInOut{Output}{输出}
\SetKw{KwTo}{to}
\SetKw{KwBy}{with step}

\SetKw{KwData}{数据}
\SetKw{KwResult}{结果}

$\bm{P} \gets \mathbf{0}$ \quad \tcp{和图像 $\bm{X}$ 大小一致的补丁掩码}
$i \gets 0$ \quad \tcp{补丁编号}

\For{$w = 0$ \KwTo $W - p$ \KwBy $s$}{
    \For{$h = 0$ \KwTo $H - p$ \KwBy $s$}{
        $\bm{P}_i \gets \bm{P}[0:end, h:h + p, w:w + p] + \mathbf{1}$\;
        $\mathbf{x}^{(i)} \gets \text{Crop}(\bm{P}_i \circ \bm{X})$ \quad \tcp{$\circ$: 哈达玛积}
        $i \gets i + 1$\;
    }
}

% $\mathbin{/\mkern-2mu/}$ 右侧边缘补丁获取\;
\tcp{右侧边缘补丁获取}
$w \gets W - p$\;

\For{$h = 0$ \KwTo $H - p$ \KwBy $s$}{
    $\bm{P}_i \gets \bm{P}[0:end, h:h + p, w:w + p] + \mathbf{1}$\;
    $\mathbf{x}^{(i)} \gets \text{Crop}(\bm{P}_i \circ \bm{X})$\;
    $i \gets i + 1$\;
}

% $\mathbin{/\mkern-2mu/}$ 底部边缘补丁获取\;
\tcp{底部边缘补丁获取}
$h \gets H - p$\;

\For{$w = 0$ \KwTo $W - p$ \KwBy $s$}{
    $\bm{P}_i \gets \bm{P}[0:end, h:h + p, w:w + p] + \mathbf{1}$\;
    $\mathbf{x}^{(i)} \gets \text{Crop}(\bm{P}_i \circ \bm{X})$\;
    $i \gets i + 1$\;
}

% $\mathbin{/\mkern-2mu/}$ 右下部分补丁获取\;
\tcp{右下部分补丁获取}
$h \gets H - p$\;
$w \gets W - p$\;
$\bm{P}_i \gets \bm{P}[0:end, h:h + p, w:w + p] + \mathbf{1}$\;
$\mathbf{x}^{(i)} \gets \text{Crop}(\bm{P}_i \circ \bm{X})$\;
\end{algorithm}

如算法 \ref{alg:patch} 所示，补丁提取的过程由以下几个步骤组成：

首先，初始化一个与输入图像 $\bm{X}$ 尺寸一致的掩码 $\bm{P}$，用于标记补丁覆盖的图像区域。
在第一个循环中，通过滑动窗口的方式提取图像的大部分补丁，
在每次迭代中，滑动窗口定位到当前区域，将对应的掩码 $\bm{P}$ 的覆盖区域值加 1，以记录该索引下的补丁位置。
随后，利用哈达玛积运算，从图像 $\bm{X}$ 中裁剪出该位置的图像补丁。

在完成主要区域的补丁提取后，需要针对图像的边缘部分进一步分解。
为了处理右侧边缘、底部边缘以及右下角区域的剩余像素，单独执行同样大小的补丁提取操作，
以确保每个像素都包含在提取的补丁中，避免出现信息丢失或分辨率不一致的问题。

最终，所有提取的补丁被存储在一个序列$\mathbf{x}$中，形成覆盖整个图像的补丁集合，同时用序列$\bm{P}_i$ 记录每个索引为i的补丁位置。
这些补丁将作为去噪扩散模型的生成先验，在训练和推理时作为噪声估计网络的原始数据。

% 如算法\ref{alg:patch}所示，首先初始化一个与输入图像 $\bm{X}$ 相同大小的掩码 $\bm{P}$，然后通过滑动窗口的方式获取图像的主要补丁。
% 在每次迭代中，将掩码 $\bm{P}$ 的相应区域加1，然后通过哈达玛积运算获取对应位置的补丁。
% 在获取完整的补丁后，我们将其存储在一个列表中，以便后续的处理。
% 最后，再通过对图像边缘的额外分解，获取右侧边缘、底部边缘和右下部分的补丁。
% 这样可以获得覆盖整个图像的补丁集合，这些补丁将作为去噪扩散模型的输入。

通过上述方式，原始图像 $\bm{X}$ 被分解为一系列补丁 ${\mathbf{x}^{(i)}}$，每个补丁提供了局部区域的对应信息。
基于补丁引导的扩散采样方法将原始的先验分布转为局部的先验分布，不仅减少了对整体图像训练时的大规模数据集的依赖，
还显著提升了模型的灵活性，使其能够适应任意分辨率的图像。
此外，这种方法通过局部补丁的去噪处理，有效地降低了全图训练可能带来的伪影和失真问题，最终实现了高质量的去噪重建。
由于扩散模型的采样对象被改为图像补丁，因此需要利用噪声估计网络预测图像补丁级别的噪声值 $\epsilon^{(i)}$，
以推断出下一时间步的输入补丁。
因此前向扩散公式\eqref{eq:q}调整为从原始图像补丁 $\mathbf{x}^{(i)}_0$ 到任意采样时间步 $t$ 中间状态 $\mathbf{x}^{(i)}_t$ 的概率分布：
\begin{equation}
    \label{eq:q-patch}
        q\left(\mathbf{x}^{(i)}_t \mid \mathbf{x}^{(i)}_0\right)=\mathcal{N}\left(\mathbf{x}^{(i)}_t ; \sqrt{\bar{\alpha}_t} \mathbf{x}^{(i)}_0,\left(1-\bar{\alpha}_t\right) \mathbf{I}\right)
\end{equation}

对于后向采样过程，原公式 \eqref{eq:p}调整为表示从当前采样时间步 $t$ 的补丁 $\mathbf{x}^{(i)}_t$ 推断上一采样时间步 $t-1$ 补丁 $\mathbf{x}^{(i)}_{t-1}$ 的概率分布：
\begin{equation}
    \label{eq:p-patch}
    p_\theta\left(\mathbf{x}^{(i)}_{t-1} \mid \mathbf{x}^{(i)}_t\right) =\mathcal{N}\left(\mathbf{x}^{(i)}_{t-1} ; \boldsymbol{\mu}_\theta\left(\mathbf{x}^{(i)}_t, t\right), \Sigma_\theta\left(\mathbf{x}^{(i)}_t, t\right)\right)
\end{equation}

噪声估计阶段的核心任务是从每个补丁中学习局部图像的先验信息。
后向过程中的均值 $\boldsymbol{\mu}_\theta$ 可进一步由以下公式计算：
\begin{equation}
    \boldsymbol{\mu}_\theta\left(\mathbf{x}^{(i)}_t, t\right)=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}^{(i)}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}^{(i)}_t, t\right)\right)
\end{equation}

图 \ref{img:patch} 给出了一种在滑动窗口步长$s$等于补丁大小$p$时的补丁分解示例，此时除边缘区域外，补丁之间不会有重叠，
从图中可以看出水下图像经过分解后，每个补丁所包含的信息更加局部化，数据的分布也随之变得更为简单。
由于每个补丁聚焦于图像的小范围区域，即使在训练数据有限的情况下，模型也能够通过学习这些简单模式，从局部色块分布中提取有效特征。
这种处理方式显著提升了模型校正水下图像色偏的能力，同时减少了全局建模的复杂性，使得训练更高效、鲁棒性更强。
\begin{figure}
    \vspace{4mm}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/ch3/patch.pdf}
    \caption{水下退化图像的补丁分解示例}
    \label{img:patch}
\end{figure}


\subsection{基于条件去噪的采样过程}

条件扩散模型在生成任务中表现出卓越的性能，被广泛应用于图像编辑和恢复任务\cite{cDDPM} \cite{rst_DDPM}。
本章利用条件扩散模型的基本原理将退化的水下图像作为条件信息引入扩散模型采样过程中，从而确保生成结果的保真度和对目标图像特征的精确还原。
\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ch3/cond_ddpm.pdf}
    \caption{基于条件去噪的采样过程示意图}
    \label{img:cond_ddpm}
\end{figure}

如图 \ref{img:cond_ddpm} 所示，在采样过程中，模型将退化的水下图像补丁 $\tilde{\mathbf{x}}^{(i)}$ 与当前时间步的输入噪声补丁 $\mathbf{x}^{(i)}_t$ 在通道维度上进行拼接，
形成一个六通道的组合图像。该组合图像随后被输入到噪声估计网络中，以从原始图像中学习带有条件的噪声分布预测。
这种设计能够有效地结合输入噪声与退化图像信息，指导模型生成具有高保真度的去噪图像。

如算法 \ref{alg:training} 所示，训练过程中首先确定一幅完整图像的所有补丁位置掩码 $\bm{P}$，
然后随机选择一个补丁编号 $i$，以获取对应的水下清晰图像补丁 $\mathbf{x}_0^{(i)}$ 和退化的条件图像补丁 $\tilde{\mathbf{x}}^{(i)}$。
按照这种随机选择策略可以增加训练时的鲁棒性，降低模型对特定补丁位置的过拟合风险。

在每次迭代中，执行以下步骤：
（1）从时间步集合 $T$ 中随机采样一个时间步长$t \sim \text{Uniform}\{1,\ldots,T\}$。
（2）从标准正态分布中生成噪声 $\bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$。
（3）根据公式\eqref{eq:x0_xt_patch}，将噪声添加到已知的目标补丁 $\mathbf{x}_0^{(i)}$中：
\begin{equation}
\label{eq:x0_xt_patch}
    \mathbf{x}_t^{(i)} = \sqrt{\bar{\alpha}_t} \mathbf{x}_0^{(i)} + \sqrt{1 - \bar{\alpha}_t} \bm{\epsilon}_t
\end{equation}

利用梯度下降算法训练的核心是优化模型参数 $\theta$，使其能够准确预测噪声 $\bm{\epsilon}_\theta$，因此目标是最小化以下损失函数：
\begin{equation}
    \nabla_{\theta}\vert\vert\bm{\epsilon}_t -  \bm{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0^{(i)}+\sqrt{1-\bar{\alpha}_t}\bm{\epsilon}_t\,,\tilde{\mathbf{x}}^{(i)},t)\vert\vert^2
\end{equation}

\begin{algorithm}
    \SetAlgoLined
    \KwIn{干净图像 $\bm{X}_0$ ，退化图像 $\bm{\tilde{X}}$，记录补丁位置的掩码 $\bm{P}$}
    \KwOut{训练后的模型参数 $\theta$}
  
    $n \leftarrow P.\text{length}$\;
    \Repeat{收敛}{
      \tcp{随机从不同的补丁位置采样一个补丁索引 $i \in \{1, 2, 3, \ldots, n\}$}
      $\mathbf{x}_0^{(i)} \leftarrow \text{Crop}(\bm{P}_i \circ \bm{X}_0)$\;
      $\tilde{\mathbf{x}}^{(i)} \leftarrow \text{Crop}(\bm{P}_i \circ \bm{\tilde{X}})$\;
      $t \sim \text{Uniform}\{1, \ldots, T\}$ 且 $\bm{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$\;
      \tcp{按以下目标执行一次梯度下降优化：}
      \quad $\nabla_{\theta} \Vert \bm{\epsilon}_t - \bm{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0^{(i)} + \sqrt{1 - \bar{\alpha}_t}\bm{\epsilon}_t, \tilde{\mathbf{x}}^{(i)}, t) \Vert^2$\;
    }
    \caption{训练}
    \label{alg:training}
  \end{algorithm}

模型推理采样过程如算法 \ref{alg:inference} 所示，采样过程中将退化的水下图像 $\tilde{\bm{X}}$ 作为条件信息，为模型提供参考。
采样图像 $\bm{X}_t$ 的初始状态为标准正态分布随机噪声：$\bm{X}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$。
在每个时间步 $s$ 中，通过退化图像补丁的指导，逐步去除噪声，生成最终清晰图像 $\bm{X}_t$。
基于去噪扩散隐式模型，如果将采样步骤数设置为 $S$，每个时间步对应一个噪声去除阶段 $t$ 和 $t_{\text{next}}$，采样过程的主要步骤如下：
（1）首先从 $n$ 个补丁掩码列表 $P$ 中，提取当前图像补丁 $\mathbf{x}_t^{(i)}$ 和条件补丁 $\tilde{\mathbf{x}}^{(i)}$。
使用训练好的噪声估计网络 $\bm{\epsilon}_\theta$，为每个补丁单独预测当前时间步的噪声补丁 $\bm{\epsilon}_\theta\left(\mathbf{x}_t^{(i)}, \tilde{\mathbf{x}}^{(i)}, t\right)$；
（2）将每个补丁的噪声预测值累加到全局噪声估计矩阵 $\bm{\hat{\epsilon}}_t$，同时更新权重矩阵 $\mathbf{M}$，用于记录每个像素的累计权重；
（3）使用逐元素除法计算全局平均噪声估计：$\bm{\hat{\epsilon}}_t \leftarrow \bm{\hat{\epsilon}}_t \oslash \mathbf{M}$；
（4）最后根据估计的全局噪声 $\bm{\hat{\epsilon}}_t$，按照公式\eqref{eq:x0_xt}更新当前时间步的图像 $\bm{X}t$。
重复上述步骤直至所有时间步 $S$ 完成，最终返回清晰图像 $\bm{X}_t$。
\begin{algorithm}[ht]
    \SetAlgoLined
    \KwIn{退化图像 $\tilde{\bm{X}}$，隐式采样时间步数 $S$，记录补丁位置的掩码 $\bm{P}$}
    \KwOut{采样后的图像 $\bm{X}_t$}
  
    $\bm{X}_{t} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$\;
    \For{$s = S,\ldots,1$}{
      $t \leftarrow (s-1) \cdot T / S + 1$\;
      \eIf{$s > 1$}{
        $t_{\text{next}} \leftarrow (s-2) \cdot T / S + 1$\;
      }{
        $t_{\text{next}} \leftarrow 0$\;
      }
      $\bm{\hat{\epsilon}}_t \leftarrow \mathbf{0}$\;
      $\mathbf{M} \leftarrow \mathbf{0}$\;
      \For{$i = 1,\ldots,n$}{
        $\mathbf{x}_t^{(i)} \leftarrow \text{Crop}(\mathbf{P}_i \circ \bm{X}_t)$\;
        $\tilde{\mathbf{x}}^{(i)} \leftarrow \text{Crop}(\mathbf{P}_i \circ \tilde{\bm{X}})$\;
        $\bm{\hat{\epsilon}}_t \leftarrow \bm{\hat{\epsilon}}_t + \mathbf{P}_i \cdot \bm{\epsilon}_{\theta}(\mathbf{x}_t^{(i)}, \tilde{\mathbf{x}}^{(i)}, t)$\;
        $\mathbf{M} \leftarrow \mathbf{M} + \mathbf{P}_i$\;
      }
      $\bm{\hat{\epsilon}}_t \leftarrow \bm{\hat{\epsilon}}_t \oslash \mathbf{M}$  \tcp* {$\oslash$: 元素级除法}
      $X_{t} \leftarrow \sqrt{\bar{\alpha}_{t_{\text{next}}}} \left(\frac{X_t - \sqrt{1 - \bar{\alpha}_t} \cdot \bm{\hat{\epsilon}}_t}{\sqrt{\bar{\alpha}_t}}\right) + \sqrt{1 - \bar{\alpha}_{t_{\text{next}}}} \cdot \bm{\hat{\epsilon}}_t$\;
    }
    \Return $\bm{X}_t$\;
    \caption{采样}
    \label{alg:inference}
  \end{algorithm}

\section{噪声估计网络结构}
目前去噪扩散模型的噪声估计网络大多基于 U-Net \cite{unet}架构，
本章分别通过修改和引入残差模块和注意力机制，设计了一种针对图像补丁规格的噪声估计网络。
噪声估计网络模型总体结构如图 \ref{img:network} 所示，采用带有跳跃连接的编码器-解码器架构，其输入为当前时间步 $t$ 的图像补丁 $\mathbf{x}^{(i)}_t$ 和对应的条件补丁 $\tilde{\mathbf{x}}^{(i)}$拼接形成的六通道张量数据。
经过初始卷积操作后，输入被送入编码器进行特征提取，经过解码器生成预测的结果$\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$。
\begin{figure}
    \centering 
    \includegraphics[width=0.8\textwidth]{figures/ch3/network.pdf}
    \caption{噪声估计网络结构示意图}
    \label{img:network}
\end{figure}

\subsection{残差模块的特征处理}
特征处理是深度学习模型中提升特征表达能力的重要步骤，尤其是在复杂任务中，深层次的特征处理可以有效提高模型的学习能力。
残差网络（Residual Network, ResNet）\cite{resnet}在特征处理任务中发挥了重要作用。通过引入跨层残差连接，ResNet 缓解了深层网络中的梯度消失问题，并显著提升了特征提取的效率和精度。
本章设计的残差模块在ResNet基础上，添加了时间步的嵌入信息，如图\ref{img:module}所示：
在每个残差模块中都加入一个经过正弦-余弦位置编码处理的时间步嵌入信息，
该时间嵌入经过全连接层后，与上一层的特征融合，建立基于不同采样时间步的特征相关性。
在卷积操作之前，模块依次执行组归一化（Group Normalization, GN）\cite{gn}、非线性激活函数（Rectified Linear Unit, ReLU）\cite{relu}和 Dropout 操作\cite{dropout}。
卷积操作后的输出会与前一层输入结合，实现跨层的残差连接。
这种设计既提升了特征的表达能力，又通过残差路径有效缓解了梯度消失问题，使模型能够更深层次地学习复杂特征。

\subsection{残差注意力模块的深度融合}
注意力机制是近年来深度学习中广泛应用的一种方法，通过捕捉特征中的全局依赖关系，显著增强了模型对关键特征的表达能力。
在本章中，我们引入了残差-注意力模块以进一步提升模型的特征提取能力，
尤其是在编码器和解码器中特定分辨率为 $16 \times 16$ 的层中（如图\ref{img:network}）。
残差注意力模块详细设计如下：
如图\ref{img:module}所示，首先对上一层输入特征进行组归一化，确保特征分布的一致性，
再经过自注意力机制捕捉输入特征中不同位置之间的全局依赖关系，
之后将经过自注意力处理的特征输入一个 $1 \times 1$ 的卷积层，用作残差连接的ShortCut层。
最后通过残差连接，将卷积层的输出与原始输入特征融合。

类似于 Transformer 中的注意力机制 \cite{2017attention}，通过引入残差路径，模块不仅增强了全局特征的感知能力，还避免了深层网络中的梯度消失问题。
残差-注意力模块的引入使模型能够在局部卷积之外关注更广范围的特征关系。特别是在处理复杂图像结构或需要全局特征分析时，该模块展现出了显著优势。
结合编码器和解码器的联合作用，模型能够更加准确地估计噪声。

\subsection{可学习的采样策略}
编码器的核心任务是逐步压缩输入特征的空间分辨率，以提取高层次特征并为解码阶段提供丰富的语义信息。
如图 \ref{img:module} 所示，本章设计的编码器中的下采样未采用传统的池化操作，而是用步长为 2 的卷积操作代替。
这种设计使下采样过程成为一个可学习的阶段，使网络能够自主优化特征压缩方式，从而更加灵活地适应输入数据的特点。

解码器通过逐步上采样还原特征的空间分辨率，最终输出预测的噪声估计结果 $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$。
上采样操作的实现方式主要包括两种：（1）线性插值结合卷积：通过插值扩展特征图尺寸，然后使用卷积操作进一步优化特征。（2）反卷积：直接通过反卷积操作增加特征的空间分辨率。
如图 \ref{img:module} 所示，本章选择了反卷积方式进行上采样，
通过反卷积操作从瓶颈层的低分辨率特征图逐步还原到输入图像的原始尺寸。
相比于线性插值结合卷积的方式，反卷积具有更强的学习能力，能够动态调整特征映射的还原方式。

此外，类似U-Net的设计，解码器中通过四次跳跃连接，将编码器中对应分辨率的特征直接传递到解码器，弥补了下采样过程中可能丢失的信息。
这种设计显著提高了生成结果的质量和一致性。算法整体采样过程如图\ref{img:sample_process}所示。
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/ch3/module.pdf}
    \caption{各模块示意图}
    \label{img:module}
    \vspace{0.4cm}
\end{figure}

\begin{figure}[ht]
    \vspace{4mm}
    \centering
    \includegraphics[width=0.98\textwidth]{figures/ch3/sample_process.pdf}
    \caption{算法整体采样过程}
    \label{img:sample_process}
\end{figure} 

\section{实验结果与分析}
\subsection{实验设置}
实验选用了两个开源的水下图像增强数据集——EUVP \cite{funie_gan} 和 UIEB \cite{uieb} 作为基准数据集，
其中EUVP 数据集包含 11,435 张成对的水下图像（paired），涵盖三种不同的风格，图像分辨率主要为 $256 \times 256$，
UIEB 数据集包含 890 张配对的水下图像（paired）以及 60 张无参考的水下图像（unpaired）。
该数据集相比EUVP拥有更高分辨率的水下图像。
图 \ref{img:scatter} 展示了两个数据集中图像分辨率的分布情况，可以看出UIEB数据集的图像分辨率规格更加多样，且大部分图像分辨率都高于EUVP数据集。
两个数据集的训练集和测试集划分情况如表 \ref{tab:dataset-split}所示。
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/ch3/scatter.pdf} \hspace{0.7cm}
    \caption{EUVP 和 UIEB 数据集中图像的分辨率分布}
    \label{img:scatter}
\end{figure}

\begin{table}[ht]
	\vspace{-0.4mm}
	\centering
	\caption{\label{tab:dataset-split}EUVP与UIEB数据集划分}
	\vspace{-2mm}
	\setlength{\tabcolsep}{2.6mm}{
		\begin{tabular}{lccc}
			\toprule
			\specialrule{0em}{1pt}{1pt}
			\textbf{数据集}  & \textbf{训练集}  & \textbf{测试集} & \textbf{共计} \\
			\hline
			\specialrule{0em}{1pt}{1pt}
			EUVP (paired) \cite{funie_gan}  & $8,363$  & $3,072$  & $11,435$\\
			\specialrule{0em}{1pt}{1pt}
                UIEB (paired) \cite{uieb}  & $678$  & $212$  & $890$\\
			\bottomrule
	\end{tabular}}
	\vspace{-1mm}
\end{table}   

实验基于 PyTorch 框架，在 NVIDIA RTX3060 GPU 上进行。
整个训练过程迭代 500,000 次，批量大小为 8。图像补丁大小设置为 $64 \times 64$，与噪声估计网络的输入维度一致。
优化器采用 Adam \cite{kingma2017adam}，学习率为 $2 \times 10^{-4}$。

去噪扩散模型采样过程的总采样步数 $T$ 设置为 1000，基于去噪扩散隐式模型的采样推理步数 $S$ 设置为 20，以加速推理。
方差调度参数 $\beta$ 采用线性变化，范围从 0.0001 逐步增加到 0.02。

\subsection{定量评价} \label{sec:quantitative}
在图像恢复领域，对恢复结果进行定量评价是至关重要的一环。本章选取了两种在图像恢复领域里广泛使用的峰值信噪比和结构相似性指数来对不同算法生成结果进行定量比较，
同时，由于水下图像的特殊性，本章还选取了一种专门的水下图像质量指标来对结果进行无参考质量评价，具体介绍如下：

（1）峰值信噪比（Peak Signal-to-Noise Ratio, PSNR）：PSNR是一种客观评价图像质量的重要指标，它通过比较图像信号的最大值与背景噪声的强弱来评估图像质量。
PSNR 首先统计了参考图像和生成结果之间的均方误差$\mathrm{MSE}$：
\begin{equation}
    \mathrm{MSE} = \frac{1}{N} \sum_{i=1}^{N} (I(i) - K(i))^2
\end{equation}

其中，$I$ 和 $K$ 分别表示参考图像和生成结果，$N$ 表示图像的像素总数。PSNR对均方误差的结果进了一定的标准化，计算方式为：
\begin{equation}
    \mathrm{PSNR} =10 \times \log _{10} \frac{(\mathrm{MAXI})^2}{\mathrm{MSE}}
\end{equation}

其中，$\mathrm{MAXI}$ 为图像的最大像素值，表示像素值的动态范围，对于8位图像，$\mathrm{MAXI}=255$。
一般来说，PSNR对光照误差敏感，能有效反映图像质量，峰值信噪比越高，图像质量通常越好。

（2）结构相似性指数（Structural Similarity Index Measure, SSIM） \cite{ssim}：SSIM通过比较图像之间的多个视觉要素来计算损失，包括亮度$l$、对比度$c$和结构$s$三个方面评价图像质量。
计算三种评价指标首先需要计算参考图像和生成结果的像素平均值$\mu_x$和$\mu_y$，以及对应的方差$\sigma_x^2$，$\sigma_y^2$和协方差$\sigma_{xy}$：
\begin{equation}
    \mu_x = \frac{1}{N} \sum_{i=1}^{N} I(i) , \quad \mu_y = \frac{1}{N} \sum_{i=1}^{N} K(i)
\end{equation}

\begin{equation}
    \sigma_x^2 = \frac{1}{N} \sum_{i=1}^{N} (I(i) - \mu_x)^2 , \quad \sigma_y^2 = \frac{1}{N} \sum_{i=1}^{N} (K(i) - \mu_y)^2
\end{equation}

\begin{equation}
    \sigma_{xy} = \frac{1}{N} \sum_{i=1}^{N} (I(i) - \mu_x)(K(i) - \mu_y)
\end{equation}

其中，$I$ 表示参考图像，$K$ 表示生成结果，$N$ 表示图像的像素总数，结合这些统计值可以计算亮度、对比度和结构三个方面的评价指标：

亮度评价指标的计算公式为：
\begin{equation}
    l(x, y) = \frac{2\mu_x\mu_y + c_1}{\mu_x^2 + \mu_y^2 + c_1}
\end{equation}

对比度评价指标的计算公式为：
\begin{equation}
    c(x, y) = \frac{2\sigma_x\sigma_y + c_2}{\sigma_x^2 + \sigma_y^2 + c_2}
\end{equation}

结构评价指标的计算公式为：
\begin{equation}
    s(x, y) = \frac{{\sigma_{xy} + c_3}}{{\sigma_x\sigma_y + c_3}}
\end{equation}

其中，常数$c_1=(255\times0.01)^2$、$c_2=(255\times0.03)^2$、$c_3=(255\times0.015)^2$ 是稳定因子，

SSIM 综合考量了亮度、对比度和结构三个方面的评价指标，具体计算公式为：
\begin{equation}
    \mathrm{SSIM} = [{{l(x,y)}^\alpha} \cdot {{c(x,y)}^\beta} \cdot {{s(x,y)}^\gamma} ]
\end{equation}

令$c_3=\frac{c_2}{2}$，$\alpha=\beta=\gamma=1$，则SSIM可以简化为：
\begin{equation}
    \mathrm{SSIM} = \frac{{(2\mu_x\mu_y + c_1)(2\sigma_{xy} + c_2)}}{{(\mu_x^2 + \mu_y^2 + c_1)(\sigma_x^2 + \sigma_y^2 + c_2)}}
\end{equation}

其中，$\mathrm{SSIM}$ 的取值范围为 $[-1, 1]$，值越大，表示生成结果在亮度、对比度和结构三个方面与参考图像越相似，图像质量越好。

（3）水下图像质量指标（Underwater Image Quality Measure, UIQM） \cite{uiqm}：UIQM是一种无参考水下图像质量评价指标，可以在没有参考图像的情况下，对生成结果进行客观评价。
对于水下图像来说，不同波长的衰减系数不同，导致图像存在色偏，正向散射效应往往会造成成像模糊，而后向散射效应限制了图像的对比度。
因此，UIQM综合考量了水下图像的色彩测量指标$\mathrm{UICM}$、清晰度测量指标$\mathrm{UISM}$和对比度测量指标$\mathrm{UIConM}$作为最终的评价指标。

$\mathrm{UICM}$通过分析图像的颜色通道差异来量化图像的色彩特性：
\begin{equation}
    \mathrm{UICM}=-0.0268 \times \sqrt{\mu_{RG}^2 + \mu_{YB}^2} + 0.1586 \times \sqrt{\sigma_{RG}^2 + \sigma_{YB}^2}
\end{equation}

其中，$\mu_{RG}$ 和 $\mu_{YB}$ 分别表示生成结果红绿两个通道的差异均值和黄蓝两个通道的差异均值，对于RGB图像来说，黄色通道可以通过计算红绿通道像素均值得到，
$\sigma_{RG}$ 和 $\sigma_{YB}$ 分别表示对应的方差。

$\mathrm{UISM}$ 通过分析图像的局部对比度来量化图像的清晰度，因此首先需要计算图像的局部对比度$\mathrm{EME}$：
\begin{equation}
    \mathrm{EME} = \frac{2}{k_1 k_2} \sum_{l=1}^{k_1} \sum_{k=1}^{k_2} \log \left( \frac{I_{\text{max},k,l}}{I_{\text{min},k,l}} \right)
\end{equation}

其中，$k_1$ 和 $k_2$ 分别表示图像的行和列的像素数，$I_{\text{max},k,l}$ 和 $I_{\text{min},k,l}$ 分别表示图像在第$k$行和第$l$列的像素最大值和最小值。

而$\mathrm{UISM}$ 为$\mathrm{EME}$的在不同通道上的加权和：
\begin{equation}
    \mathrm{UISM} = 0.299 \times \mathrm{EME}_{R} + 0.587 \times \mathrm{EME}_{G} + 0.114 \times \mathrm{EME}_{B}
\end{equation}

$\mathrm{UIConM}$ 通过衡量图像中最亮和最暗部分的区分度来量化图像的对比度，首先需要在图像对应的灰度图像中计算平均灰度值$\mu$：
\begin{equation}
   \mu = \frac{1}{N} \sum_{i=1}^{N} x_i
\end{equation}

其中，$N$ 表示图像的像素总数，$x_i$ 表示图像的第$i$个像素的灰度值。然后计算灰度图的标准差 \(\sigma\)即为UIConM值：
\begin{equation}
    \mathrm{UIConM}=\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2} 
\end{equation}

结合以上色彩测量指标 UICM、清晰度测量指标 UISM 和对比度测量指标 UIConM的计算方式，UIQM 以加权平均的方式计算最终的水下图像评价指标：
\begin{equation}
    \mathrm{UIQM}=c_1 \times \mathrm{UICM}+c_2 \times \mathrm{UISM}+c_3 \times \mathrm{UIConM}
\end{equation}

其中，常数$c_1=0.0282$、$c_2=0.2953$、$c_3=3.5753$为权重系数。

表\ref{tab:psnr-ssim}  和表\ref{tab:uiqm} 分别列出了本章提出的水下图像增强的方法与其他主流方法在 PSNR、SSIM 和 UIQM 等指标上的比较结果。
需要说明的是，Ucolor\cite{ucolor}模型需要额外的传输图作为输入，
而DCP系列方法可以生成额外的传输图，在Ucolor所提出的原始方法中，使用一般暗通道\cite{GDCP}提取所需的传输图，但是其在水下水下的适应性较差。
鉴于本章的实验对象包含其水下变体UDCP\cite{udcp}算法，所以这里使用UDCP算法生成的传输图来为Ucolor模型提供必要的数据。

实验结果表明本章提出的水下图像增强方法在多个指标上表现优越，
对于有参考指标来说，本章提出的方法在EUVP数据集上PSNR指标提升了2.83dB，SSIM指标提升了0.03，说明本章提出的方法在生成结果的多种视觉要素方面与参考图像更加相似，
在UIEB数据集上PSNR指标与SSIM指标也能接近或超越其他方法。
对于无参考指标来说，本章提出的方法首先在UICM、UISM和UIConM指标上拥有更加均衡的提升，
EUVP数据集与UIEB数据集在综合水下图像质量指标UIQM上分别提升了0.01和0.12，
说明本章提出的方法在提升增强图像的细节质量与全局一致性方面具有明显优势，可以有效提升水下图像的视觉效果。

\begin{table*}[t]
	\footnotesize
        \captionsetup{justification=centering}
	\caption{不同方法在数据集 EUVP 和 UIEB 上的 PSNR 和 SSIM 定量结果}
	\label{tab:psnr-ssim}
	\vspace{-0.4mm}
	\centering
	\setlength{\tabcolsep}{1.01mm}{
		\renewcommand{\arraystretch}{1.1}
            \begin{tabular}{cccccccccc}
			\toprule
			数据集 & 指标 & UDCP\cite{udcp} & UGAN\cite{ugan} & FGAN\cite{funie_gan} & UWCNN\cite{uwcnn} & Ucolor\cite{ucolor} & STSC\cite{stsc} & U-shape\cite{u-shape} & Ours\\
			\hline
			\multirow{2}{*}{EUVP} & \textbf{PSNR} & $16.71$ & $27.46$ & $26.59$ & $21.56$ & $26.27$ & $20.71$ & $26.23$ & $\textcolor{red}{\textbf{30.29}}$ \\ & \textbf{SSIM} & $0.76$ & $0.87$ & $0.84$ & $0.84$ & $0.89$ & $0.83$ & $0.88$ & $\textcolor{red}{\textbf{0.92}}$ \\
            \vspace{-2mm} 
             \hspace*{\fill} \\
			% \hline
            
			\multirow{2}{*}{UIEB} & \textbf{PSNR} & $13.20$ & $21.01$ & $20.76$ & $14.86$ & $\textcolor{red}{\textbf{23.90}}$ & $21.46$ & $20.94$ & $21.34$ \\ & \textbf{SSIM}  & $0.70$ & $0.69$ & $0.68$ & $0.69$ & $0.91$ & $0.72$ & $0.62$ & $\textcolor{red}{\textbf{0.92}}$  \\
			\bottomrule
	\end{tabular}}
	\vspace{-0.4mm}
\end{table*}   % paired

\begin{table*}[t]
	%	\vspace{-4mm}
	\footnotesize
	\caption{不同方法在数据集 EUVP 和 UIEB 上的 UIQM 定量结果}
	\label{tab:uiqm}
	\vspace{-0.4mm}
	\centering
	\setlength{\tabcolsep}{1.01mm}{
		\renewcommand{\arraystretch}{1.1}
		% \begin{tabular}{c|c|ccccccc|c}
            \begin{tabular}{cccccccccc}
			\toprule
			数据集 & 指标 & UDCP\cite{udcp} & UGAN\cite{ugan} & FGAN\cite{funie_gan} & UWCNN\cite{uwcnn} & Ucolor\cite{ucolor} & STSC\cite{stsc} & U-shape\cite{u-shape} & Ours\\
			\hline
			\multirow{4}{*}{EUVP} & UICM & $\textcolor{red}{\textbf{5.85}}$ & $3.76$ & $4.54$ & $2.97$ & $3.94$ &  $5.31$ & $4.16$ & $4.67$ \\
			& UISM & $6.28$ & $7.40$ & $7.15$ & $6.85$ & $7.33$ & $\textcolor{red}{\textbf{7.41}}$ & $7.29$ & $7.25$\\
                & UIConM & $0.03$ & $0.22$ & $0.20$ & $0.29$ & $0.27$ &
            $0.28$ & $0.27$ & $\textcolor{red}{\textbf{0.30}}$\\
                 % \cline{2-10}
                & \textbf{UIQM} & $2.13$ & $3.08$ & $2.97$ & $3.15$ & $3.25$ &
            $3.34$ & $3.22$ & $\textcolor{red}{\textbf{3.35}}$ \\
            \vspace{-2mm} 
             \hspace*{\fill} \\
			% \hline
			\multirow{4}{*}{UIEB} & UICM & $\textcolor{red}{\textbf{6.70}}$ & $5.63$ & $5.44$ & $2.69$ & $5.06$ & $5.80$ & $4.91$ & $5.28$ \\
			& UISM & $5.42$ & $5.35$ & $5.24$ & $4.98$ & $6.74$ & $5.25$ & $5.32$ & $\textcolor{red}{\textbf{7.08}}$\\
                & UIConM & $0.04$ & $0.29$ & $0.29$ & $0.31$ & $0.30$ &
            $\textcolor{red}{\textbf{0.33}}$ & $0.32$ & $0.30$\\
                % \cline{2-10}
                & \textbf{UIQM} & $1.97$ & $2.77$ & $2.74$ & $2.65$ & $3.20$ &
            $2.89$ & $2.86$ & $\textcolor{red}{\textbf{3.32}}$\\
			\bottomrule
	\end{tabular}}
	\vspace{-0.4mm}
\end{table*}   

\subsection{主观评价}
从图\ref{img:scatter} EUVP 和 UIEB 数据集图像的分辨率分布中可以看出，基准数据集中的图像分辨率大小并不一致，
而大多数基于深度学习的水下图像增强方法，例如 FGAN\cite{funie_gan}、UGAN\cite{ugan}、U-shape\cite{u-shape} 和 STSC\cite{stsc}，
均是在固定的输入和输出尺寸（$256 \times 256$）下进行训练和推理，这会在一定程度上限制方法的适用性。

如图\ref{img:visual-euvp}和图\ref{img:visual-uieb}所示，本章首先在$256 \times 256$的固定图像分辨率尺寸下实验对比了不同方法在 EUVP 和 UIEB 数据集上的主观增强效果。
在EUVP数据集上，本章提出的水下图像增强方法在多数情况下能够取得更好的视觉效果，生成结果可以保持更加丰富的色彩和对比度，
例如图\ref{img:visual-euvp}第三行的结果中，本章的方法相比如其他方法可以更好地恢复物体的颜色信息，图像整体视觉效果更加自然，不会出现边缘伪影等问题。
对于UIEB数据集，由于其原始图像分辨率较大（图\ref{img:visual-uieb}中标注为 “*” 的方法限制图像分辨率为 $256 \times 256$），在进行压缩时会丢失较多的图像细节，因此多种方法的生成结果在视觉效果上较为相似，
但是本章的方法依旧在亮度、对比度、饱和度等指标上表现出良好的质量，尤其在蓝色和绿色主导的水域场景中，可以增强画面色彩饱和度和自然感。
\begin{figure}[t]
    \vspace{1mm}
	\begin{center}
		\begin{tabular}{ccccccccc}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Input/264318_n02655020_17544.JPEG} & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UDCP/264318_n02655020_17544.JPEG}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UGAN/264318_n02655020_17544.JPEG}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/FGAN/264318_n02655020_17544.JPEG}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UWCNN/264318_n02655020_17544.JPEG} & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ucolor/264318_n02655020_17544.JPEG}& \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/STSC/264318_n02655020_17544.JPEG}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ushape/264318_n02655020_17544.JPEG}& \hspace{-0.40cm} 
            \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ours/264318_n02655020_17544..png}  \\
                
            \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Input/265613_n01496331_8134.JPEG}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UDCP/265613_n01496331_8134.JPEG}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UGAN/265613_n01496331_8134.JPEG}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/FGAN/265613_n01496331_8134.JPEG}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UWCNN/265613_n01496331_8134.JPEG}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ucolor/265613_n01496331_8134.JPEG} & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/STSC/265613_n01496331_8134.JPEG}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ushape/265613_n01496331_8134.JPEG} & \hspace{-0.40cm}         
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ours/265613_n01496331_8134..png}   \\

            \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Input/264298_00035269.jpg}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UDCP/264298_00035269.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UGAN/264298_00035269.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/FGAN/264298_00035269.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UWCNN/264298_00035269.jpg}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ucolor/264298_00035269.jpg} & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/STSC/264298_00035269.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ushape/264298_00035269.jpg} & \hspace{-0.40cm}         
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ours/264298_00035269.png}   \\

            \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Input/im_f149_.jpg}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UDCP/im_f149_.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UGAN/im_f149_.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/FGAN/im_f149_.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/UWCNN/im_f149_.jpg}  & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ucolor/im_f149_.jpg} & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/STSC/im_f149_.jpg}   & \hspace{-0.40cm}
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ushape/im_f149_.jpg} & \hspace{-0.40cm}  
			\includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/EUVP/Ours/im_f149_.png}   
            \\
			\scriptsize Input
			&\hspace{-0.50cm} \scriptsize UDCP\cite{udcp}
			&\hspace{-0.50cm} \scriptsize UGAN\cite{ugan}
			&\hspace{-0.50cm} \scriptsize FGAN\cite{funie_gan}
			&\hspace{-0.50cm} \scriptsize UWCNN\cite{uwcnn}
			&\hspace{-0.50cm} \scriptsize Ucolor\cite{ucolor}
			&\hspace{-0.50cm} \scriptsize STSC\cite{stsc}
			&\hspace{-0.50cm} \scriptsize U-shape\cite{u-shape}
			&\hspace{-0.50cm} \scriptsize Ours
			\\

		\end{tabular}
	\end{center}
	\vspace{-0.4mm}
	\caption{\label{img:visual-euvp}EUVP 数据集上不同模型结果的主观比较}
	\vspace{-0.3mm}
\end{figure} 

\begin{figure*}[t]
    \vspace{-1mm}
\begin{center}
    \begin{tabular}{ccccccccc}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Input/161_img_.png} & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/UDCP/161_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/UGAN/161_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/FGAN/161_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/UWCNN/161_img_.png} & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Ucolor/161_img_.png}& \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/STSC/161_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Ushape/161_img_.png}& \hspace{-0.40cm} 
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Ours/161_img_.png}  \\

        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Input/41_img_.png} & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/UDCP/41_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/UGAN/41_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/FGAN/41_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/UWCNN/41_img_.png} & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Ucolor/41_img_.png}& \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/STSC/41_img_.png}  & \hspace{-0.40cm}
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Ushape/41_img_.png}& \hspace{-0.40cm} 
        \includegraphics[width = 0.10\linewidth,height=0.10\linewidth]{figures/ch3/compare/UIEB/Ours/41_img_.png} 
        \\
        \scriptsize Input
        & \hspace{-0.51cm} \scriptsize UDCP\cite{udcp}
        & \hspace{-0.51cm} \scriptsize UGAN*\cite{ugan}
        & \hspace{-0.51cm} \scriptsize FGAN*\cite{funie_gan}
        & \hspace{-0.51cm} \scriptsize UWCNN\cite{uwcnn}
        & \hspace{-0.51cm} \scriptsize Ucolor\cite{ucolor}
        & \hspace{-0.51cm} \scriptsize STSC*\cite{stsc}
        & \hspace{-0.51cm} \scriptsize U-shape*\cite{u-shape}
        & \hspace{-0.51cm} \scriptsize Ours
        \\
    \end{tabular}
\end{center}
\vspace{-1mm}
\caption{\label{img:visual-uieb}UIEB 数据集上不同模型结果的主观比较}
\vspace{-1mm}
\end{figure*}

为了进一步探明本章方法在高分辨率图像上的增强效果并与其他固定图像尺寸的方法进行对比，因此还对UIEB数据集进行了保持原始分辨率效果的对比实验。
对于存在输入大小限制的四种模型（FGAN\cite{funie_gan}、UGAN\cite{ugan}、U-shape\cite{u-shape} 和 STSC\cite{stsc}）使用线性插值来调整其生成结果的图像分辨率，
结果如图\ref{img:visual-detail}所示，
可以看出本章提出的水下图像增强方法可以在不损失图像原始细节的情况下对任意分辨率的水下图像进行有效增强，在保留物体表面的细节纹理的同时增强色彩和对比度，
相比于其他模型具有明显的优势。

\begin{figure}[ht]
    \vspace{1mm}
	\begin{center}
        \includegraphics[width=0.96\linewidth]{figures/ch3/compare/discussion/res_detail.jpg}
		\\
        \setlength{\tabcolsep}{0pt} % 默认通常是6pt
        \begin{tabular}{
            >{\centering\arraybackslash}p{0.16\linewidth}
            >{\centering\arraybackslash}p{0.16\linewidth}
            >{\centering\arraybackslash}p{0.16\linewidth}
            >{\centering\arraybackslash}p{0.16\linewidth}
            >{\centering\arraybackslash}p{0.16\linewidth}
            >{\centering\arraybackslash}p{0.16\linewidth}
        }
            \footnotesize Input \hspace{-1.5cm}
			& \footnotesize FGAN\cite{funie_gan} 
			& \footnotesize UGAN\cite{ugan} 
			& \footnotesize STSC\cite{stsc} 
			& \footnotesize U-shape\cite{u-shape} 
			& \footnotesize Ours
            \\ 
		\end{tabular}
	\end{center}
	\caption{ \label{img:visual-detail}UIEB 数据集中不同分辨率图像的增强结果比较}
	\vspace{-2mm}
\end{figure}

\subsection{结果讨论}
\subsubsection{水下语义恢复}
为了验证提出的水下图像增强算法在减轻水下环境对图像语义干扰上的有效性，
本章实验选取了一种显著性区域检测网络 \cite{sod} 用来对比原始退化图像与增强后图像显著性区域检测结果。
如图 \ref{img:sod} 所示，本章的水下图像增强方法可以在一定程度上提升水下图像的语义信息，
使得原本模糊和难以分辨的图像显著性区域在经过算法增强后得到缓解，
这种提升可以让算法更好地支持如目标检测和语义分割等图像处理的下游任务。
\begin{figure}[ht]
	\begin{center}
		\begin{tabular}{ccccccccc}
            \vspace{-0.5mm}  
            \raisebox{0.8cm}{\footnotesize Input}   & \hspace{-0.36cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/1.JPEG} & \hspace{-0.43cm} 
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/2.JPEG}  & \hspace{-0.43cm} 
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/3.jpg}  & \hspace{-0.43cm}  
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/4.jpg}  & \hspace{-0.43cm} 
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/5.JPEG}  & \hspace{-0.43cm} 
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/6.jpg}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/7.JPEG}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/original/9.jpg} \\
            
            \vspace{-0.5mm} 
            \raisebox{0.8cm}{\footnotesize SOD}   & \hspace{-0.36cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/1.JPEG} & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/2.JPEG}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/3.jpg}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/4.jpg}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/5.JPEG}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/6.jpg}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/7.JPEG}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/9.jpg}  \\
            
            \vspace{-0.5mm} 
            \raisebox{0.8cm}{\footnotesize Output} & \hspace{-0.36cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/1.png} & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/2.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/3.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/4.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/5.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/6.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/7.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/output/9.png} \\
            
            \vspace{-0.5mm} 
            \raisebox{0.8cm}{\footnotesize SOD} & \hspace{-0.36cm} 
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/1.png} & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/2.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/3.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/4.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/5.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/6.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/7.png}  & \hspace{-0.43cm}
            \includegraphics[width = 0.10\linewidth, height=0.10\linewidth]{figures/ch3/compare/discussion/SOD/sod/9.png}  \\
		\end{tabular}
	\end{center}
	\caption{\label{img:sod}原始图像与增强后的图像在显著性区域检测任务中的对比}
	\vspace{-2mm}
\end{figure}     % sod

\subsubsection{网络架构讨论}
为了探讨网络架构对模型性能的影响，本章对不同网络组件进行了消融实验（如表 \ref{tab:ablation} 所示）。
实验重点分析了时间步嵌入与残差注意力模块对模型的最终表现的影响，以及模型在质量与效率之间的权衡。
结果表明，在编码器-解码器的残差模块中去除时间步嵌入（w/o timestep）会明显降低模型对采样时间步的敏感性，从而无法更准确地识别扩散过程中的动态变化，模型精度大大折扣，
在所有层中引入残差注意力模块（w/ all layer attention）可以一定程度上提升模型的特征提取能力，但运行时间增加至 1022.20 ms，显著增加了模型的时间开销。
相比之下，仅在一层中加入残差注意力模块（w/ one layer attention）时，可以有效减低推理成本，同时模型在PSNR和SSIM指标上不会出现明显下降。
因此本章最终为了平衡性能和效率，仅在特征分辨率为 $16 \times 16$ 的特定层中引入残差注意力模块（如图\ref{img:network}所示）。
\begin{table}[ht]
    \vspace{-0.4mm}
    \centering
    \caption{\label{tab:ablation}消融实验结果}
    \setlength{\tabcolsep}{2.6mm}{
        \begin{tabular}{lcccc}
            \toprule
            \specialrule{0em}{1pt}{1pt}
            \textbf{}  & \textbf{PSNR}  & \textbf{SSIM} & \textbf{UIQM} & \textbf{Runtime (ms)} \\
            \hline
            \specialrule{0em}{1pt}{1pt}
            w/o timestep & $21.75$  & $0.84$  & $3.00$ & $\textcolor{red}{\textbf{739.20}}$\\
            \specialrule{0em}{1pt}{1pt}
            w/ all layer attention & $\textcolor{red}{\textbf{31.02}}$  & $\textcolor{red}{\textbf{0.92}}$  & $\textcolor{red}{\textbf{3.05}}$ & $1022.20$\\
            \specialrule{0em}{1pt}{1pt}
            w/ one layer attention & $29.90$  & $0.91$  & $3.04$ & $889.32$\\
            \bottomrule
    \end{tabular}}
    \vspace{1mm}
\end{table}

\subsubsection{步长与采样步数的均衡}
除了模型架构，滑动窗口步长 ($stride$) 和采样步数 ($S$) 也是影响模型推理时间的重要因素。
本章最后进一步探讨了滑动窗口步长 ($stride$) 和采样步数 ($S$) 对生成图像质量和时间开销的影响，以探讨如何在质量与效率之间取得最佳平衡。
如图\ref{img:stride-S}(a)所示，当滑动窗口步长等于补丁大小（$stride=64$）时，补丁之间完全独立，导致过渡区域会出现明显的拼接痕迹；
当滑动窗口步长略小于补丁大小（如 $stride=52/48$）时，补丁之间有适当重叠，重叠区域通过均值采样实现自然的过渡效果，从而生成更平滑、无明显伪影的图像；
进一步减小滑动窗口步长（如 $stride=32/16$）时，生成结果无明显提升，但其计算复杂度会对应增加。

在基于去噪扩散隐式模型的采样过程中，适当减少采样步数 $S$ 能够显著加速反向去噪过程，但也会对最终生成结果产生负面影响。
如图 \ref{img:stride-S}(b) 所示，采样步数过小（如 $S=2$）时，生成图像的质量明显下降，具有明显的伪影；
当 $S$ 增加至 10 或 15 时，生成效果显著提升，接近最优结果。
进一步增加 $S$（如 $S=20$）时，生成质量提升趋于稳定，说明适当的采样步数已足够实现高质量图像生成。
\begin{figure}[ht]
    \begin{center}
        \begin{tabular}{ccccccc}
            \multicolumn{1}{c}{(a)} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/input/im_f545_.jpg} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_stride/stride64/im_f545_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_stride/stride52/im_f545_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_stride/stride48/im_f545_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_stride/stride32/im_f545_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_stride/stride16/im_f545_.png} \\
            \multicolumn{1}{c}{} & \small Input & \hspace{-0.36cm} \small $stride=64$ & \hspace{-0.36cm} \small $stride=52$ & \hspace{-0.36cm} \small $stride=48$ & \hspace{-0.36cm} \small $stride=32$ & \hspace{-0.36cm} \small $stride=16$ \\
        \end{tabular} 
        \vspace{5mm}
        \begin{tabular}{ccccccc}
            \multicolumn{1}{c}{(b)} &  \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/input/im_f565_.jpg} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_s/s2/im_f565_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_s/s5/im_f565_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_s/s10/im_f565_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_s/s15/im_f565_.png} & \hspace{-0.46cm}
            \includegraphics[width=0.15\linewidth]{figures/ch3/compare/discussion/diff_s/s20/im_f565_.png} \\
            
            \multicolumn{1}{c}{} & \small Input & \hspace{-0.36cm} \small $S=2$ & \hspace{-0.36cm} \small $S=5$ & \hspace{-0.36cm} \small $S=10$ & \hspace{-0.36cm} \small $S=15$ & \hspace{-0.36cm} \small $S=20$ \\
        \end{tabular}
    \end{center}
    \vspace{-6mm}
    \caption{\label{img:stride-S} 不同步长$stride$ 和 采样步数$S$ 的结果}
    \vspace{-4mm}
\end{figure}

为了进一步验证步长与采样步数的均衡关系，以及检查模型在新样本下的泛化能力，
本章利用预训练模型在 RUIE \cite{RUIE} 数据集上进行了参数交叉的对比实验。
如图 \ref{img:param} 所示，即便采样步数 $S$ 较小或滑动窗口步长$stride$较大，在某些组合下依然能获得良好的增强效果，
这说明$S$和$stride$在一定程度上具有互补性，比如较小的步长使得更多的重叠区域参与信息交互，使得能够在较少的采样步数下获得令人满意的结果。
\begin{figure}
    \centering
    \includegraphics[width=0.98\linewidth]{figures/ch3/compare/discussion/param.pdf}
    \caption{\label{img:param}不同步长$stride$和采样步数$S$的结果}
\end{figure}

\section{本章小结}
本章提出了一种基于去噪扩散模型的水下图像增强方法，采用补丁引导的采样策略，摆脱对数据集规模的依赖，同时实现保持原有分辨率的水下图像的生成。
并且重新调整了适用于补丁大小的噪声估计网络，通过优化各个模块的结构，提升噪声预测的精度。
最后通过与不同基线模型进行对比实验，验证了本章提出的方法在主观视觉效果和客观指标上的出色表现，并进一步讨论了模型架构以及自定义参数对模型性能的影响。



